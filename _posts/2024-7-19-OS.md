---
layout: post

title: OS
categories: [OS，八股]
tags: [OS,八股]
typora-root-url: ..
---



## 八股-背诵

### 操作系统及驱动

#### 线程与进程

##### 进程有几种状态？画一下进程状态转换图？

![截屏2024-06-09 17.50.15](./assets/pics/%E6%88%AA%E5%B1%8F2024-06-09%2017.50.15.png)

##### 什么是进程？什么是线程？他们的区别？

进程是资源分配的基本单位，它是程序执行时的一个实例，在程序运行时创建。

线程是程序执行的最小单位，是进程的一个执行流，一个进程由多个线程组成的。

**区别：**

1. 进程是资源分配的最小单位，线程是系统调度的单位，两者均可并发执行。
2. 进程有自己的**独立地址空间**，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据，使用**相同的地址空间**， 因此，CPU切换一个线程的花费远比进程小很多，同时创建一个线程的开销也比进程小很多。
3. 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。
4. **进程切换时，消耗的资源大，效率低。**所以涉及到频繁的切换时，使用线程要好于进程。同样如果要求同时进行并且又要共享某些变量的并发操作，只能用线程不能用进程。
5. 执行过程：**每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口**。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
6. 线程执行开销小，**但是不利于资源的管理和保护**。线程适合在SMP机器（双CPU系统）上运行。进程执行开销大，但是能够很好的进行资源管理和保护，可以跨机器迁移。

##### 什么是内核线程和用户线程？

内核级别线程是内核可感知的，用内核负责创建与管理的线程。

用户级别线程是内核感知不到的，由用户负责管理与创建的。

##### 内核线程和用户线程有什么优缺点？

1. 管理：内核线程由操作系统内核来创建和管理的线程，它是由操作系统调度器调度的。用户线程是由用户应用程序自己管理的线程，它是在用户空间中运行。

2. 创建和销毁：内核线程是由操作系统内核来调度和管理的，而用户线程则是由用户程序来实现调度。因此，在线程的创建和销毁方面，内核线程比用户线程消耗更多的系统资源和时间。

3. 访问资源：由于内核线程是由操作系统内核来管理的，所以它可以直接访问操作系统内核的资源， 如系统调用和底层硬件设备等。而用户线程只能访问用户空间的资源，如应用程序的数据和内存 等，而无法直接访问操作系统内核的资源。

4. 线程切换：由于内核线程是由操作系统内核来管理的，所以线程切换需要从用户态切换到内核态， 这个过程需要进行上下文切换，切换代价较高。而用户线程则是在用户态下运行的，线程的切换代 价相对较低。

5. 并发性：内核线程可以在多个CPU上并发执行，因为内核线程可以被分配到任何一个可用的CPU 上。用户线程只能在单个CPU上执行。

```
用户级多线程对于处理逻辑并行性问题有很好的效果。不擅长于解决物理并行问题。
内核级多线程适用于解决物理并行性问题。
```

##### 何时使用多进程，何时使用多线程？

对资源的管理和保护要求高，不限制开销和效率时，使用多进程。

要求效率高，频繁切换时，资源的保护管理要求不是很高时，使用多线程。

##### 进程通信方式（IPC internel process communication）

**1.pipe** 

​	特指无名管道，只能半双工通信，实质是一个内核缓冲区，只能在父子进程之间使用。可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

**2.fifo**

​	 特指有名管道，也是半双工通信，只要确定名称其可以在没有血缘关系的进程间通信。fifo通过mknode()系统调用或者mkfifo()函数来建立的。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。

**3.消息队列**

​	消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表，存放在内核中并由消息队列标识符标识。消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。 每个数据块都被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。

​	消息队列也克服了管道通信方式中信号量有限的缺点，具有写权限的进程可以按照一定的规则向消息队列中添加新信息；对消息队列有读权限的进程则可以从消息队列中读取信息。

​	消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。

​	可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。

**4.信号**

​	信号是一种比较复杂的通信方式，是在软件层次上对中断机制的一种模拟，它是一种异步通信方式（也是进程通信中唯一一个异步的通信方式），也是比较复杂的通信方式，用于通知进程有某事件发生，一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。

​	信号可以直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。

​	如果该进程当前并未处于执行态，则该信号就由内核保存起来，直到该进程恢复执行再传递给它。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。（理解）

用户进程对信号的响应方式

​	忽略信号：就是对信号不做任何处理，但是有两个信号不能忽略：SIGKILL及SIGSTOP。

​	捕捉信号：定义信号处理函数，当信号发生时，执行相应的处理函数。

​	执行缺省操作：Linux对每种信号都规定了默认操作

**5.共享内存**

​	共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。共享内存可以说这是最有用的进程间通信方式。

**6.信号量**

​	信号量本质上是一个计数器，它和管道有所不同，它不以传送数据为主要目的，主要作为进程之间及同一种进程的不同线程之间的同步和互斥手段，它常作为一种锁机制，可以用来控制多个进程对共享资源的访问，防止某进程正在访问共享资源时，其他进程也访问该资源，使得资源在一个时刻只有一个进程独享。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

**7.socket**

​	Socket应该属于RPC



#### 死锁

**必要条件**

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

**处理方法**

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

**死锁恢复**

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

**死锁预防**

在程序运行之前预防发生死锁。

**1. 破坏互斥条件**

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

2. **破坏占有和等待条件**

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

3. **破坏不可抢占条件**

4. **破坏环路等待**

给资源统一编号，进程只能按编号顺序来请求资源。

**死锁避免**

银行家算法

##### 解释下虚拟地址、逻辑地址、线性地址、物理地址、总线地址？

**逻辑地址：**我们程序员写代码时给出的地址叫逻辑地址，其中包含段选择子和偏移地址两部分。

**线性地址：**通过分段机制，将逻辑地址转换后的地址，叫做线性地址。而这个线性地址是有个范围的， 这个范围就叫做线性地址空间，32 位模式下，线性地址空间就是 4G。

**物理地址：**就是真正在内存中的地址，它也是有范围的，叫做物理地址空间。那这个范围的大小，就取 决于你的内存有多大了。

**虚拟地址：**如果没有开启分页机制，那么线性地址就和物理地址是一一对应的，可以理解为相等。如果 开启了分页机制，那么线性地址将被视为虚拟地址，这个虚拟地址将会通过分页机制的转换，最终转换 成物理地址。

**总线地址**是指在x86下的I/O地址，ARM下的物理地址。（在x86下，外设的I/O地址是独立的，即有专门 的指令访问外设I/O，I/O地址就是“总线地址”，而RAM地址就是“物理地址”。在ARM下，I/O和RAM统一 编址，但linux为了统一各个平台，仍然保留这个概念，总线地址其实就是物理地址。）

IO内存空间，统一编址，设备地址作为内存的扩展，一般嵌入式用这种 IO端口空间，

独立编址，设备地址独立编制，一般用于x86，了解即可

##### 简述处理器在读内存过程中，CPU、MMU、cache、内存如何协同工作？

​	首先执行在用户空间的程序在被创建的时候就被分配了一片独立的虚拟地址空间，自下而上应该是代码段(.txt .rodata)，数据段（.data .bss），堆区，栈区。这里的地址是内核分配的虚拟地址，当程序需要访存的时候，每个进程都有自己的上下文，里面包含页表基址寄存器，里面存着页表基址，如果是三级页表，则虚拟地址可以被看作四部分，基址加上第一段便宜确定二级页表的基址，然后加上第二段偏移拿到三级页表地址，随后根据最后一段偏移量得到物理地址，随后物理地址命中cache的话则不用访问内存，不然根据相应的算法例如LRU算法更新cache，其中物理地址和虚拟地址转换的部分是可以通过专用的MMU完成。

##### 内存非连续分配管理的三种方式

**分页存储管理：**优点是不需要连续的内存空间，且内存利用率高（只有很小的页内碎片）；缺点是 不易于实现内存共享与保护。

**分段存储管理：**优点是易于实现段内存共享和保护；缺点是每段都需要连续的内存空间，且内存利 用率较低（会产生外部碎片）。

**段页式存储管理（对每个段分页存储）**：优点是不需要连续的内存空间，内存利用率高（只有很小 的页内碎片），且易于实现段内存共享和保护；缺点是管理软件复杂性较高，需要的硬件以及占用 的内存也有所增加，使得执行速度下降。

##### 什么是快表，你知道多少关于快表的知识？

**快表**，又称联想寄存器(TLB) ，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若 干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。

![截屏2024-06-09 17.47.32](./assets/pics/%E6%88%AA%E5%B1%8F2024-06-09%2017.47.32.png)

##### 虚拟内存是什么？

虚拟内存是一种计算机内存管理技术，它可以将物理内存和磁盘空间结合起来，让操作系统可以在物理 内存不足的情况下运行更多的应用程序。它通过将应用程序使用的内存分为虚拟页面（虚拟地址空间） 和物理页面（物理地址空间），并使用分页机制将虚拟页面映射到物理页面上来实现。

当应用程序需要访问一个虚拟页面时，操作系统将根据页面映射表将虚拟页面映射到物理页面上，如果该页面不在物理内存中，操作系统将会将其中的一部分数据存储到磁盘中，并将该页面从物理内存中移除。当应用程序需要再次访问该页面时，操作系统会将该页面从磁盘中加载回物理内存中，这个过程称 为页面调度或页面置换。

**虚拟内存的目的是什么？**

虚拟地址的优点

1. 扩大可用内存：虚拟内存可以将物理内存和磁盘空间结合起来，以实现更大的可用内存。在物理内 存不足时，虚拟内存可以将不常用的页面从物理内存中移除，并将它们暂时保存在磁盘上。这样， 系统就可以用磁盘空间来模拟更大的物理内存。

2. 保护内存：虚拟内存可以实现地址空间隔离，使每个应用程序都拥有自己独立的虚拟地址空间。这 样，应用程序就无法访问其他应用程序的内存，从而增强了系统的安全性。

3. 简化内存管理：虚拟内存可以使内存管理更加灵活和高效。它可以将内存分为多个页面，并使用页 面置换算法来管理内存。这样，操作系统就可以按需加载页面，并将不常用的页面从物理内存中移 除，从而实现更高效的内存管理。






#### 阻塞非阻塞 异步同步（理解）

排列组合得到同步阻塞，同步非阻塞，异步阻塞，异步非阻塞。

##### 阻塞与非阻塞

阻塞和非阻塞是进程在访问数据的时候，数据是否准备就绪的一种处理方式。当数据没有准备的时候，阻塞需要等待调用结果返回之前，进程会被挂起，函数只有在得到结果之后才会返回。非阻塞和阻塞的概念相对，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。

##### 同步与异步

同步指的是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。异步的概念和同步相对，当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

![在这里插入图片描述](./assets/pics/e165e93a245241c4a71f981d8605b242.png)

对于主线程上执行的一系列代码块，当其中的某个代码块需要与相关线程交互，而调用了一个函数时：

如果立即去执行此函数，这称为同步。

如果没有去执行此函数，而是将执行此函数的时机安排在未来的某个时间，然后马上继续执行刚才的代码块，这称为异步。

当执行此函数时，直至获得完整的资源之前，都暂停执行当前的代码块，这称为阻塞。

当执行此函数时，立即获得瞬时的结果，然后马上继续执行当前的代码块。如果获得的瞬时资源不是完整的资源，之后周期性发送类似的请求，直至获得完整的资源，这称为非阻塞。

​	同步/异步，在于调用函数的方式

​	阻塞/非阻塞，在于资源获取的方式

同步阻塞，立即调用函数/子进程，如果没有获得资源，则等待。

同步非阻塞，理解调用函数/子进程，如果没有获得资源，休眠或周期检查

异步阻塞，交与调度器调度，如果没有获得资源则等待。

异步非阻塞，交与调度器调度，如果没有获取资源，休眠或周期调度

##### **以io为例**

同步和异步IO的概念： 	

同步是用户线程发起I/O请求后需要等待或者轮询内核I/O操作完成后才能继续执行 	

异步是用户线程发起I/O请求后仍需要继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数 

阻塞和非阻塞IO的概念： 	
阻塞是指I/O操作需要彻底完成后才能返回用户空间 	

非阻塞是指I/O操作被调用后立即返回一个状态值，无需等I/O操作彻底完成

同步阻塞方式：    发送方发送请求之后一直等待响应。    接收方处理请求时进行的IO操作如果不能马上等到返回结果，就一直等到返回结果后，才响应发送方，期间不能进行其他工作。 

同步非阻塞方式： 发送方发送请求之后，一直等待响应。 接受方处理请求时进行的IO操作如果不能马上的得到结果，就立即返回，取做其他事情。 但是由于没有得到请求处理结果，不响应发送方，发送方一直等待。 当IO操作完成以后，将完成状态和结果通知接收方，接收方再响应发送方，发送方才进入下一次请求过程。（实际不应用） 

异步阻塞方式： 发送方向接收方请求后，不等待响应，可以继续其他工作。 接收方处理请求时进行IO操作如果不能马上得到结果，就一直等到返回结果后，才响应发送方，期间不能进行其他操作。 （实际不应用） 

异步非阻塞方式： 发送方向接收方请求后，不等待响应，可以继续其他工作。 接收方处理请求时进行IO操作如果不能马上得到结果，也不等待，而是马上返回去做其他事情。 当IO操作完成以后，将完成状态和结果通知接收方，接收方再响应发送方。（效率最高）

#### IO多路复用

Linux 服务器处理网络请求有三种机制，select、poll、epoll。也就是IO多路复用。

##### **阻塞IO存在的问题**

![图片](./assets/pics/202406072225591.jpg)

1. 进程在 recv 的时候大概率会被阻塞掉，导致一次进程切换；
2. 当 TCP 连接上的数据到达服务端的网卡、并从网卡复制到内核空间 socket 的数据等待队列时，进程会被唤醒，又是一次进程切换；并且，在用户进程继续执行完 recvfrom() 函数系统调用，将内核空间的数据拷贝到了用户缓冲区后，用户进程才会真正拿到所需的数据进行处理；
3. 一个进程同时只能等待一条连接，如果有很多并发，则需要很多进程；

总结：一次数据到达会进行**两次进程切换，**一次数据读取有**两处阻塞，单进程对单连接**。

进程A让出CPU发生进程切换，从另外一个进程切换到进程A。

阻塞等待数据到达主机，阻塞等待数据从内核空间拷贝到用户空间。

##### **非阻塞 IO**

​	为了解决同步阻塞 IO 的问题，操作系统提供了非阻塞的 recv() 函数，这个函数的效果是：如果没有数据从网卡到达内核 socket 的等待队列时，系统调用会直接返回，而不是阻塞的等待。

![图片](./assets/pics/202406072219021.jpg)

​	从上图中，我们知道，非阻塞 IO，是将等待数据从网卡到达 socket 内核空间这一部分变成了非阻塞的，用户进程调用 recvfrom() 会重复发送请求检查数据是否到达内核空间，如果没有到，则立即返回，不会阻塞。不过，当数据已经到达内核空间的 socket 的等待队列后，用户进程依然要等待 recvfrom() 函数将数据从内核空间拷贝到用户空间，才会从 recvfrom() 系统调用函数中返回。

​	非阻塞 IO 模型解决了“**两次进程切换，两处阻塞，单进程对单连接**”中的“**两处阻塞**”问题，将“**两处阻塞**”变成了“**一处阻塞**”，但依然存在“**两次进程切换，一处阻塞，单进程对单连接**”的问题。

![图片](./assets/pics/202406072225828.jpg)

​	从上图可知，系统调用 select 函数阻塞执行并返回数据就绪的连接个数，然后调用 recvfrom() 函数将到达内核空间的数据拷贝到用户空间，尽管这两个阶段都是阻塞的，但是由于只会处理有数据到达的连接，整体效率会有极大的提升。

##### IO**多路复用**

​	要解决“**两次进程切换，单进程对单连接**”的问题，服务器引入了 IO 多路复用技术，通过一个进程处理多个 TCP 连接，不仅降低了服务器处理网络请求的进程数，而且不用在每个连接的数据到达时就进行进程切换，进程可以一直运行并只处理有数据到。

![图片](./assets/pics/202406072227362.jpg)

​	到这里，阻塞 IO 模型的“**两次进程切换，两处阻塞，单进程对单连接**”问题，通过非阻塞 IO 和多路复用技术，就只剩下了“**一处阻塞**”这个问题，即 Linux 服务器上用户进程一定要等待数据从内核空间拷贝到用户空间，如果这个步骤也变成非阻塞的，也就是进程调用 recvfrom 后立刻返回，内核自行去准备好数据并将数据从内核空间拷贝到用户空间、再 notify 通知用户进程去读取数据，那就是 **IO 异步调用**，不过，Linux 没有提供异步 IO 的实现，真正意义上的网络异步 IO 是 Windows 下的 IOCP（IO 完成端口）模型，这里就不探讨了。

##### **select poll epoll**

##### 1. 功能

select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。

- select 会修改描述符，而 poll 不会；
- select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制；
- poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
- 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。

##### 2. 速度

select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。

##### 3. 可移植性

几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。

epoll

​	epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。



​	select poll是自己维护需要监视的事件，都是同步IO，既可以阻塞也可以非阻塞，因为有时间参数。

```
int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

​	epoll是交与内核托管需要监听的时间。

##### **Unix5**种IO模型

Unix 有五种 I/O 模型：

阻塞式 I/O

​	应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。

​	应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。

非阻塞式 I/O

​	应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。

​	由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。

I/O 复用（select 和 poll）

​	使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。

​	它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。

​	如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

信号驱动式 I/O（SIGIO）

​	应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

​	相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

异步 I/O（AIO）

​	应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。

​	异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

##### **五大 I/O 模型比较**

- 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
- 异步 I/O：第二阶段应用进程不会阻塞。

​	同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。
