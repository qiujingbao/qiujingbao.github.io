---
layout: post

title: DRM_GEM_2
categories: [DRM]
tags: [DRM,GEM,MMAP,BASE]
typora-root-url: ..
---

很奇怪的是在上篇文章中gem的cma实现，vma实现以及mm实现中我们都没有看到与PRIME相关的代码，可以从ioctl函数中看到，dumb的实现是基于上述文章实现的其本质是基于shmem机制实现也就是mmap。那么在gem子系统中并不仅仅只管理这个基于内存的buf。

```
Dumb Buffer
Dumb Buffer 只支持连续物理内存，基于kernel中通用CMA API实现。多用于小分辨率简单场景。

Prime Buffer
Prime是DRM中的跨设备缓冲区共享框架，最初是为多GPU平台创建的。对于用户空间，Prime缓冲区是基于dma-buf是基于dma-buf 实现，可以是连续物理内存，也可以离散的物理内存，多用于大内存复杂场景。

版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。
                        
原文链接：https://blog.csdn.net/dljaye/article/details/105591399
```

那么本篇文章的内容便是大致浏览dma-buf。

## DMA-BUF

### 历史

dma-buf 最初的原型为 shrbuf，由 Marek Szyprowski （Samsung）于2011年8月2日首次提出，他实现了 “Buffer Sharing” 的概念验证（Proof-of-Concept），并在三星平台的 V4L2 驱动中实现了 camera 与 display 的 buffer 共享问题。该 patch 发表后，在内核社区引起了巨大反响，因为当时关于 buffer 共享问题很早就开始讨论了，但是由于内核没有现成的框架支持，导致各个厂商实现的驱动五花八门，此时急需要一个统一的框架来解决 buffer 共享问题。

LWN: Buffer sharing proof-of-concept
LWN: Sharing buffers between devices
于是 Sumit Semwal (Linaro) 基于 Marek Szyprowski 的 patch 重构了一套新的框架，也就是我们今天看到的 dma-buf 核心代码，它经历了社区开发人员给出的重重考验，并最终于 2012 年 2 月 merge 到了 Linux-3.3 主线版本中，这也是 dma-buf 的第一个正式版本。此后 dma-buf 被广泛应用于内核多媒体驱动开发中，尤其在 V4L2、DRM 子系统中得到了充分应用。

LWN: DMA buffer sharing in 3.3
Patch: dma-buf: Documentation for buffer sharing framework
Patch: dma-buf: Introduce dma buffer sharing mechanism
第一个使用 dma-buf 的 DRM 分支: drm-prime-dmabuf

##### **引入dma-buf机制的原因**

- 之前内核中缺少一个可以让不同设备、子系统之间进行内存共享的统一机制。
- 混乱的共享方法：
  - V4L2(video for Linux)使用`USERPTR`的机制来处理访问来自其他设备内存的问题，这个机制需要借助于以后空间的mmap方法。
  - 类似的，wayland和x11各自定义了客户端和主进程之间的内存共享机制，而且都没有实现不同设备间内存共享的机制。
  - 内核中各种soc厂商的驱动、各种框架和子系统都各自实现各自的内存共享机制。  
- 之前共享方式存在问题：
  - 使用用户层的mmap机制实现内存共享方式太过简单粗暴，难以移植。
  - 没有统一的内存共享的API接口。

##### **dma_buf是一种怎样的存在**

dma_buf是内核中一个独立的子系统，提供了一个让不同设备、子系统之间进行共享缓存的统一框架，这里说的缓存通常是指通过DMA方式访问的和硬件交互的内存。 比如，来自摄像头采集的通过pciv驱动传输的内存、gpu内部管理的内存等等。

其实一开始，dma_buf机制在内核中的主要运用场景是支持GPU驱动中的`prime`机制，但是作为内核中的通用模块，它的适用范围很广。

dma_buf子系统包含三个主要组成:

1. dma-buf对象，它代表的后端是一个sg_table,它暴露给应用层的接口是一个文件描述符，通过传递描述符达到了交互访问dma-buf对象，进而最终达成了 共享访问sg_table的目的。
2. fence对象, which provides a mechanism to signal when one device as finished access.
3. reservation对象, 它负责管理缓存的分享和互斥访问。.

上述都是抄的，大佬们已经总结的很好了。

```
https://saiyn.github.io/homepage/2018/04/18/linux-kernel-dmabuf/
https://blog.csdn.net/hexiaolong2009/article/details/102596744
```

### 思想

DMA_BUF框架下主要有两个角色对象，一个是`exporter`，相当于是buffer的生产者，相对应的是`importer`或者是`user`,即buffer的消费使用者。

假设驱动A想使用由驱动B产生的内存，那么我们称B为exporter,A为importer.

The exporter

- 实现struct dma_buf_ops中的buffer管理回调函数。
- 允许其他使用者通过dma_buf的sharing APIS来共享buffer。
- 通过struct dma_buf结构体管理buffer的分配、包装等细节工作。
- 决策buffer的实际后端内存的来源。
- 管理好scatterlist的迁移工作。

The buffer-usr

- 是共享buffer的使用者之一。
- 无需关心所用buffer是哪里以及如何产生的。
- 通过struct dma_buf_attachment结构体访问用于构建buffer的scatterlist,并且提供将buffer映射到自己地址空间的机制。

dma-buf 的出现就是为了解决各个驱动之间 buffer 共享的问题，因此它本质上是 buffer 与 file 的结合，即 dma-buf 既是块物理 buffer，又是个 linux file。buffer 是内容，file 是媒介，只有通过 file 这个媒介才能实现同一 buffer 在不同驱动之间的流转。

一个典型的 dma-buf 应用框图如下：


通常，我们将分配 buffer 的模块称为 exporter，将使用该 buffer 的模块称为 importer 或 user。但在本系列文章中，importer 特指内核空间的使用者，user 特指用户空间的使用者。

有的人习惯将 exporter 说成是生产者，importer 说成是消费者，我个人认为这样的说法并不严谨。举例来说，Android 系统中，graphic buffer 都是由 ION 来分配的，GPU 负责填充该 buffer，DPU 负责显示该 buffer。那么在这里，ION 则是 exporter，GPU 和 DPU 则都是 importer。但是从生产者/消费者模型来讲，GPU 则是生产者，DPU 是消费者，因此不能片面的认为 exporter 就是生产者。

### 代码

```
kernel/drivers/dma-buf
```

基本对象的关系如下：

![CleanShot 2024-12-28 at 15.03.00](./assets/pics/CleanShot%202024-12-28%20at%2015.03.00.png)

```
从 linux-4.19 开始，map_atomic 接口被废弃，map 和 mmap 接口不再被强制要求。
相关提交记录参考何小龙大佬的文章
https://blog.csdn.net/hexiaolong2009/article/details/102596744
```

#### 子系统初始化

```
static int __init dma_buf_init(void)
{
	dma_buf_mnt = kern_mount(&dma_buf_fs_type);
	if (IS_ERR(dma_buf_mnt))
		return PTR_ERR(dma_buf_mnt);

	mutex_init(&db_list.lock);
	INIT_LIST_HEAD(&db_list.head);
	dma_buf_init_debugfs();
	return 0;
}
subsys_initcall(dma_buf_init);
```

可以看到该子系统在subsys_initcall被初始化。这个函数初始化几个全局变量。

```
struct dma_buf_list {
	struct list_head head;
	struct mutex lock;
};
/* 用于管理全局的dma-buf */
static struct dma_buf_list db_list;

static struct vfsmount *dma_buf_mnt;

/* 这个应该是创建虚拟文件系统用以dma-buf的file功能 */
static struct vfsmount *dma_buf_mnt;
dma_buf_mnt = kern_mount(&dma_buf_fs_type);
static struct file_system_type dma_buf_fs_type = {
	.name = "dmabuf",
	.mount = dma_buf_fs_mount,
	.kill_sb = kill_anon_super,
};
static struct dentry *dma_buf_fs_mount(struct file_system_type *fs_type,
		int flags, const char *name, void *data)
{
	return mount_pseudo(fs_type, "dmabuf:", NULL, &dma_buf_dentry_ops,
			DMA_BUF_MAGIC);
}
```

#### dma_buf_export

最上层的函数应该是这个，创建一个新的dma_buf，并将anon文件与此缓冲区相关联，以便导出。意思就是生产者到处需要导出的buffer，然后生成文件描述符并传递给其他程序。

```
/**
 * dma_buf_export - Creates a new dma_buf, and associates an anon file
 * with this buffer, so it can be exported.
 * Also connect the allocator specific data and ops to the buffer.
 * Additionally, provide a name string for exporter; useful in debugging.
 *
 * @exp_info:	[in]	holds all the export related information provided
 *			by the exporter. see &struct dma_buf_export_info
 *			for further details.
 *
 * Returns, on success, a newly created dma_buf object, which wraps the
 * supplied private data and operations for dma_buf_ops. On either missing
 * ops, or error in allocating struct dma_buf, will return negative error.
 *
 * For most cases the easiest way to create @exp_info is through the
 * %DEFINE_DMA_BUF_EXPORT_INFO macro.
 */
struct dma_buf *dma_buf_export(const struct dma_buf_export_info *exp_info)
{
	struct dma_buf *dmabuf;
	struct reservation_object *resv = exp_info->resv;
	struct file *file;
	size_t alloc_size = sizeof(struct dma_buf);
	int ret;

	if (!exp_info->resv)
		alloc_size += sizeof(struct reservation_object);
	else
		/* prevent &dma_buf[1] == dma_buf->resv */
		alloc_size += 1;

	if (WARN_ON(!exp_info->priv
			  || !exp_info->ops
			  || !exp_info->ops->map_dma_buf
			  || !exp_info->ops->unmap_dma_buf
			  || !exp_info->ops->release
			  || !exp_info->ops->map
			  || !exp_info->ops->mmap)) {
		return ERR_PTR(-EINVAL);
	}

	if (!try_module_get(exp_info->owner))
		return ERR_PTR(-ENOENT);

	dmabuf = kzalloc(alloc_size, GFP_KERNEL);
	if (!dmabuf) {
		ret = -ENOMEM;
		goto err_module;
	}

	dmabuf->priv = exp_info->priv;
	dmabuf->ops = exp_info->ops;
	dmabuf->size = exp_info->size;
	dmabuf->exp_name = exp_info->exp_name;
	dmabuf->owner = exp_info->owner;
	init_waitqueue_head(&dmabuf->poll);
	dmabuf->cb_excl.poll = dmabuf->cb_shared.poll = &dmabuf->poll;
	dmabuf->cb_excl.active = dmabuf->cb_shared.active = 0;
#if defined(CONFIG_DEBUG_FS)
	dmabuf->ktime = ktime_get();
#endif

	if (!resv) {
		resv = (struct reservation_object *)&dmabuf[1];
		reservation_object_init(resv);
	}
	dmabuf->resv = resv;
/* 生成一个新的文件描述符，用以关联这块buffer */
	file = dma_buf_getfile(dmabuf, exp_info->flags);
	if (IS_ERR(file)) {
		ret = PTR_ERR(file);
		goto err_dmabuf;
	}

	file->f_mode |= FMODE_LSEEK;
	dmabuf->file = file;
/* 初始化消费者链表 */
	mutex_init(&dmabuf->lock);
	spin_lock_init(&dmabuf->name_lock);
	INIT_LIST_HEAD(&dmabuf->attachments);

/* 加入到全局链表 */
	mutex_lock(&db_list.lock);
	list_add(&dmabuf->list_node, &db_list.head);
	mutex_unlock(&db_list.lock);

	return dmabuf;

}
EXPORT_SYMBOL_GPL(dma_buf_export);
```

#### dma_buf_fd

导出这个文件描述符，上个函数只是生成，这个导出。

```
/**
 * dma_buf_fd - returns a file descriptor for the given dma_buf
 * @dmabuf:	[in]	pointer to dma_buf for which fd is required.
 * @flags:      [in]    flags to give to fd
 *
 * On success, returns an associated 'fd'. Else, returns error.
 */
int dma_buf_fd(struct dma_buf *dmabuf, int flags)
{
	int fd;

	if (!dmabuf || !dmabuf->file)
		return -EINVAL;

	fd = get_unused_fd_flags(flags);
	if (fd < 0)
		return fd;

	fd_install(fd, dmabuf->file);

	return fd;
}
EXPORT_SYMBOL_GPL(dma_buf_fd);
```

#### dma_buf_get/put

上面那个是根据buf得到fd，这个是根据fd得到buf

```
/**
 * dma_buf_get - returns the dma_buf structure related to an fd
 * @fd:	[in]	fd associated with the dma_buf to be returned
 *
 * On success, returns the dma_buf structure associated with an fd; uses
 * file's refcounting done by fget to increase refcount. returns ERR_PTR
 * otherwise.
 */
struct dma_buf *dma_buf_get(int fd)
{
	struct file *file;

	file = fget(fd);

	if (!file)
		return ERR_PTR(-EBADF);

	if (!is_dma_buf_file(file)) {
		fput(file);
		return ERR_PTR(-EINVAL);
	}

	return file->private_data;
}
EXPORT_SYMBOL_GPL(dma_buf_get);

```

```
/**
 * dma_buf_put - decreases refcount of the buffer
 * @dmabuf:	[in]	buffer to reduce refcount of
 *
 * Uses file's refcounting done implicitly by fput().
 *
 * If, as a result of this call, the refcount becomes 0, the 'release' file
 * operation related to this fd is called. It calls &dma_buf_ops.release vfunc
 * in turn, and frees the memory allocated for dmabuf when exported.
 */
void dma_buf_put(struct dma_buf *dmabuf)
{
	if (WARN_ON(!dmabuf || !dmabuf->file))
		return;

	fput(dmabuf->file);
}
EXPORT_SYMBOL_GPL(dma_buf_put);
```

#### 直接使用ops

```
EXPORT_SYMBOL_GPL(dma_buf_attach);
EXPORT_SYMBOL_GPL(dma_buf_detach);
EXPORT_SYMBOL_GPL(dma_buf_map_attachment);
EXPORT_SYMBOL_GPL(dma_buf_unmap_attachment);
EXPORT_SYMBOL_GPL(dma_buf_kmap);
EXPORT_SYMBOL_GPL(dma_buf_mmap);
EXPORT_SYMBOL_GPL(dma_buf_vmap);
EXPORT_SYMBOL_GPL(dma_buf_vunmap);
EXPORT_SYMBOL_GPL(dma_buf_get_flags);
EXPORT_SYMBOL_GPL(dma_buf_get_uuid);
```

#### drm中prime-buf使用dma-buf

```
kernel/drivers/gpu/drm/drm_prime.c
static const struct dma_buf_ops drm_gem_prime_dmabuf_ops =  {
	.attach = drm_gem_map_attach,
	.detach = drm_gem_map_detach,
	.map_dma_buf = drm_gem_map_dma_buf,
	.unmap_dma_buf = drm_gem_unmap_dma_buf,
	.release = drm_gem_dmabuf_release,
	.map = drm_gem_dmabuf_kmap,
	.unmap = drm_gem_dmabuf_kunmap,
	.mmap = drm_gem_dmabuf_mmap,
	.vmap = drm_gem_dmabuf_vmap,
	.vunmap = drm_gem_dmabuf_vunmap,
	.get_uuid = drm_gem_dmabuf_get_uuid,
};
```

从上述代码来看，drm的prime buf是通过实现dma-buf接口来实现的。然后被广泛应用在上层应用中，比如：

```
static const struct dma_buf_ops rockchip_drm_gem_prime_dmabuf_ops = {
	.attach = drm_gem_map_attach,
	.detach = drm_gem_map_detach,
	.map_dma_buf = drm_gem_map_dma_buf,
	.unmap_dma_buf = drm_gem_unmap_dma_buf,
	.release = drm_gem_dmabuf_release,
	.map = drm_gem_dmabuf_kmap,
	.unmap = drm_gem_dmabuf_kunmap,
	.mmap = drm_gem_dmabuf_mmap,
	.vmap = drm_gem_dmabuf_vmap,
	.vunmap = drm_gem_dmabuf_vunmap,
	.begin_cpu_access = rockchip_drm_gem_dmabuf_begin_cpu_access,
	.end_cpu_access = rockchip_drm_gem_dmabuf_end_cpu_access,
	.begin_cpu_access_partial = rockchip_drm_gem_begin_cpu_access_partial,
	.end_cpu_access_partial = rockchip_drm_gem_end_cpu_access_partial,
};
```

##### 如何使用dma-buf/prime-buf

**导出缓冲区**：

- 导出方（Exporter）使用 `DEFINE_DMA_BUF_EXPORT_INFO()` 定义导出实例，并调用 `dma_buf_export()` 将私有缓冲区对象封装为 `&dma_buf`。
- 然后通过 `dma_buf_fd()` 将该 `&dma_buf` 导出为用户空间的文件描述符。

**共享缓冲区**：

- 用户空间将文件描述符传递给需要共享此缓冲区的所有驱动程序。
- 在内核中，文件描述符通过 `dma_buf_get()` 转换为 `&dma_buf`。
- 使用 `dma_buf_attach()` 将缓冲区附加到设备上。
- **注意**：在这一阶段，导出方仍可以自由迁移或重新分配缓冲区的底层存储。

**启动 DMA 访问**：

- 缓冲区附加到所有设备后，用户空间可以发起对共享缓冲区的 DMA 访问。
- 在内核中，通过调用 `dma_buf_map_attachment()` 和 `dma_buf_unmap_attachment()` 来完成 DMA 访问的映射和解除映射。

**清理资源**：

- 驱动程序完成对共享缓冲区的使用后，需要调用 `dma_buf_detach()` 解除缓冲区的附加关系（在清理所有映射后）。
- 然后调用 `dma_buf_put()` 释放通过 `dma_buf_get()` 获取的引用。
