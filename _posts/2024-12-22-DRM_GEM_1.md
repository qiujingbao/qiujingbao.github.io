---
layout: post

title: DRM_GEM_1
categories: [DRM]
tags: [DRM,GEM,MMAP,BASE]
typora-root-url: ..
---

### 在rk-sdk中使用bear构建跳转数据库

```
cd ./kernel
make clean
```

```
sudo apt-get install bear
```

```
./build.sh
bear -- make ARCH=$RK_ARCH $RK_KERNEL_DEFCONFIG $RK_KERNEL_DEFCONFIG_FRAGMENT
bear -- make ARCH=$RK_ARCH $RK_KERNEL_DTS.img -j$RK_JOBS
mv ./compile_commands.json ../
./build.sh kernel
```

### GEM与TTM之间的关系

上篇文章讨论了，应用层如何通过libdrm进行图像操作的。这篇文章主要看gem。通过如下资料

```
https://www.kernel.org/doc/html/v4.9/gpu/drm-mm.html 内核文档
https://lwn.net/Articles/283798/ 这个网站介绍了linux的演变过程
```

```
We've spent the last couple of weeks writing a different manager for the
kernel, called 'gem' (for 'graphics execution manager'). It takes the
lessons we've learned from TTM and constructs just the API we need to
implement the dri_bufmgr interface.
```

```
GEM与TTM之间的关系
TTM是内核最初的DRM显存管理器，其设计思想是试图为所有的显卡驱动提供一个公共的API。TTM后面被认为是失败的，其API与实现复杂不可控，没有人愿意用他。后来intel吸取教训，设计了GEM，其设计较为灵活，只提供基本的实现，部分功能需要驱动程序通过驱动自定的接口进行扩展。GEM与TTM在特性上的主要区别为GEM不支持管理独立显存，只支持UMA，而TTM两种都支持。目前的DRM驱动程序中，基本都使用GEM作为前端为用户态提供接口，而涉及到管理独立显存的时候，则借助TTM作为后端实现管理功能。
```

可以看到gem从ttm演变过来，ttm暂时忽略。

```
-----

                  The Graphics Execution Manager
	       Part of the Direct Rendering Manager
                  ==============================
		  
		 Keith Packard <keithp@keithp.com>
		   Eric Anholt <eric@anholt.net>
			     2008-5-9

Contents:

 1. GEM Overview
 2. API overview and conventions
 3. Object Creation/Destruction
 4. Reading/writing contents
 5. Mapping objects to userspace
 6. Memory Domains
 7. Execution (Intel specific)
 8. Other misc Intel-specific functions

1. Graphics Execution Manager Overview
```

### GEM Overview

```
Graphics Execution Manager（GEM）是一种内存管理方法。由于视频存储器的大小增加以及诸如OpenGL之类的图形API的日益复杂性，从性能角度看，在每个上下文切换处重新初始化图形卡状态的策略过于低效。另外，现代linux桌面还需要一种最佳方式与合成管理器（compositing manager）共享屏幕外缓冲区。这些要求诞生开发了用于管理内核内部图形缓冲区的新方法，图形执行管理方法（GEM）是其中一种。
```

```
Gem is designed to manage graphics memory, control access to the graphics
device execution context and handle the essentially NUMA environment unique
to modern graphics hardware. Gem allows multiple applications to share
graphics device resources without the need to constantly reload the entire
graphics card. Data may be shared between multiple applications with gem
ensuring that the correct memory synchronization occurs.
Gem旨在管理图形内存，控制对图形设备执行上下文的访问，并处理现代图形硬件特有的NUMA环境。
Gem允许多个应用程序共享图形设备资源，而无需不断重新加载整个图形卡。
数据可以在多个应用程序之间共享，gem确保发生正确的内存同步。

Graphics data can consume arbitrary amounts of memory, with 3D applications
constructing ever larger sets of textures and vertices. With graphics cards
memory space growing larger every year, and graphics APIs growing more
complex, we can no longer insist that each application save a complete copy
of their graphics state so that the card can be re-initialized from user
space at each context switch. Ensuring that graphics data remains persistent
across context switches allows applications significant new functionality
while also improving performance for existing APIs.

图形数据可能会消耗任意量的内存，3D应用程序会构建更大的纹理和顶点集。
随着图形卡内存空间逐年增加，图形API变得越来越复杂，我们不能再坚持每个应用程序保存其图形状态的完整副本，以便可以在每次上下文切换时从用户空间重新初始化卡。
确保图形数据在上下文切换中保持持久性，可以让应用程序获得重要的新功能，同时还可以提高现有API的性能。

Modern linux desktops include significant 3D rendering as a fundemental
component of the desktop image construction process. 2D and 3D applications
paint their content to offscreen storage and the central 'compositing
manager' constructs the final screen image from those window contents.  This
means that pixel image data from these applications must move within reach
of the compositing manager and used as source operands for screen image
rendering operations.

现代linux桌面包括重要的3D渲染，作为桌面图像构建过程的基本组成部分。
2D和3D应用程序将其内容绘制到屏幕外存储中，中央“合成管理器”根据这些窗口内容构建最终的屏幕图像。
这意味着来自这些应用程序的像素图像数据必须在合成管理器的范围内移动，并用作屏幕图像渲染操作的源操作数。

Gem provides simple mechanisms to manage graphics data and control execution
flow within the linux operating system. Using many existing kernel
subsystems, it does this with a modest amount of code.

Gem提供了简单的机制来管理linux操作系统中的图形数据和控制执行流。
使用许多现有的内核子系统，它只需要少量的代码就可以做到这一点。

```

### API Overview and Conventions

```
2. API Overview and Conventions

All APIs here are defined in terms of ioctls appplied to the DRM file
descriptor. To create and manipulate objects, an application must be
'authorized' using the DRI or DRI2 protocols with the X server. To relax
that, we will need to implement some better access control mechanisms within
the hardware portion of the driver to prevent inappropriate
cross-application data access.

这里的所有API都是根据应用于DRM文件描述符的ioctl定义的。
要创建和操作对象，应用程序必须使用DRI或DRI2协议与X服务器进行“授权”。
为了放松这一点，我们需要在驱动程序的硬件部分实现一些更好的访问控制机制，以防止不适当的跨应用程序数据访问。

Any DRM driver which does not support GEM will return -ENODEV for all of
these ioctls. Invalid object handles return -EINVAL. Invalid object names
return -ENOENT. Other errors are as documented in the specific API below.

任何不支持GEM的DRM驱动程序都将为所有这些ioctl返回-ENODEV。
无效的对象句柄返回-EINVAL。无效的对象名返回-ENOENT。其他错误记录在下面具体的API中。

To avoid the need to translate ioctl contents on mixed-size systems (with
32-bit user space running on a 64-bit kernel), the ioctl data structures
contain explicitly sized objects, using 64-bits for all size and pointer
data and 32-bits for identifiers. In addition, the 64-bit objects are all
carefully aligned on 64-bit boundaries. Because of this, all pointers in the
ioctl data structures are passed as uint64_t values. Suitable casts will
be necessary.

为了避免需要在混合大小的系统（32位用户空间在64位内核上运行）上翻译iocTL内容，iocTL数据结构包含显式大小的对象，所有大小和指针数据使用64位，标识符使用32位。
此外，64位对象都在64位边界上仔细对齐。因此，ioctel数据结构中的所有指针都作为uint64_t值传递。需要合适的石膏。

One significant operation which is explicitly left out of this API is object
locking. Applications are expected to perform locking of shared objects
outside of the GEM api. This kind of locking is not necessary to safely
manipulate the graphics engine, and with multiple objects interacting in
unknown ways, per-object locking would likely introduce all kinds of
lock-order issues. Punting this to the application seems like the only
sensible plan. Given that DRM already offers a global lock on the hardware,
this doesn't change the current situation.
这个API中明确遗漏的一个重要操作是对象锁定。
应用程序预计将在GEM api之外执行共享对象的锁定。这种锁定不是安全操纵图形引擎所必需的，并且随着多个对象以未知方式交互，每个对象的锁定可能会引入各种锁顺序问题。
将其应用于应用程序似乎是唯一明智的计划。鉴于DRM已经在硬件上提供了全局锁定，这并不能改变当前的情况。
```

### 代码阅读

上面是官方给的介绍，看着有点迷糊。下面结合代码来看。主要涉及如下文件。

```
kernel/drivers/gpu/drm/drm_gem.c
kernel/drivers/gpu/drm/drm_gem_cma_helper.c
kernel/drivers/gpu/drm/drm_gem_framebuffer_helper.c
kernel/drivers/gpu/drm/drm_mm.c
kernel/drivers/gpu/drm/drm_vma_manager.c
kernel/drivers/gpu/drm/drm_vm.c
```

```
kernel/include/drm/drm_gem_cma_helper.h
kernel/include/drm/drm_gem_framebuffer_helper.h
kernel/include/drm/drm_gem_cma_helper.h
kernel/include/drm/drm_vma_manager.h
kernel/include/drm/drm_mm.h
```

那么上述gem与cma有什么区别和联系呢？

```
连续内存分配器（cma）在早期引导时保留一个内存池，用于服务对大块连续内存的请求。
DRM GEM/CMA助手使用此分配器作为提供内存中物理连续的缓冲区对象的手段。这对于无法通过IONMC映射分散缓冲区的显示驱动程序非常有用。
```

下面是有位大佬的解释。

```
CMA Helper
CMA 是 Contiguous Memory Allocator 的缩写，它本身指代的是一种内存分配器（或内存分配策略），专用于分配物理连续的大块内存，以满足大内存需求的设备（如 Display、Camera）。CMA 除了具有内存分配的功能外，还具有内存迁移的功能，使得同一块 CMA 区域既可以被系统使用也可以被专用的 DMA 设备占用，从而大大提高了内存的使用率。要想使用 CMA 内存，需要在内核配置中开启 CONFIG_CMA 配置宏。

CMA helper 则是 DRM 驱动中一组通用的 GEM API，专用于分配、访问物理连续的系统内存，对于那些不带 IOMMU 或不具有专用显存的 Display 硬件而言，极大的方便了它们的 DRM 驱动开发，其中最典型的例子就是 tinydrm 驱动。CMA helper 最早由 Sascha Hauer（来自德国 Pengutronix 公司）基于三星 Exynos 平台开发，并于 2012 年 9 月合入 linux-3.7 主线。

需要注意的是，DRM 中的 CMA helper 和 CMA 本身没有直接关系， 即使当前内核没有使能 CONFIG_CMA，也不影响 DRM CMA helper 的使用。CMA helper 的内存分配接口使用的是 dma_alloc_wc()，而内核 CMA 分配器本身是和 DMA 子系统无缝衔接的，当内核开启 CONFIG_CMA 时，dma_alloc_wc() 后端可以采用 CMA 来分配一致性内存；当内核关闭 CONFIG_CMA 配置时，dma_alloc_wc() 则采用系统默认的页分配器来分配连续的物理内存。至于为何要用“CMA”关键字来给 DRM helper 函数命名，这里直接引用作者原话：

The code technically does not depend on CMA as the backend allocator, the name has been chosen because cma makes for a nice, short but still descriptive function prefix.

—— 摘自：[PATCH v4] DRM: add drm gem CMA helper
本来 Sascha 想用 “dma_alloc” 这个关键字，但后来发现这会使函数名变得特别啰嗦，因此最终决定使用 “CMA” 关键字代替。

版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。                  
原文链接：https://blog.csdn.net/hexiaolong2009/article/details/108655052
```

![CleanShot 2024-12-24 at 20.25.15](./assets/pics/CleanShot%202024-12-24%20at%2020.25.15.png)

从上图来看也可以看到，`CMA`只是使用了`gem`框架实现了`CMA`分配的一套通用的接口和实现。



```
vma管理器负责将任意依赖于驱动程序的内存区域映射到线性用户地址空间。它为调用者提供偏移量，然后可以在drm设备的address_space上使用。它注意不要重叠区域，适当调整它们的大小，不要用不一致的伪vm_pgoff字段混淆mm核心。
驱动程序不应将其用于VMEM中的对象放置。此管理器应仅用于管理到线性用户空间VM的映射。
我们使用drm_mm作为后端来管理对象分配。但它针对alloc/free调用而不是查找进行了高度优化。因此，我们使用rb树来加速偏移查找。
```



下面先分析对象，在了解函数流程。

![CleanShot 2024-12-24 at 20.26.54](./assets/pics/CleanShot%202024-12-24%20at%2020.26.54.png)





对于drm_device的初始化包含两部分，

- drm_dev_init
- drm_dev_register

第一个是init

```
int drm_dev_init(struct drm_device *dev,
		 struct drm_driver *driver,
		 struct device *parent)
{
	int ret;
...
	kref_init(&dev->ref);
	dev->dev = get_device(parent);
	dev->driver = driver;
...
	dev->anon_inode = drm_fs_inode_new();
	if (IS_ERR(dev->anon_inode)) {
		ret = PTR_ERR(dev->anon_inode);
		DRM_ERROR("Cannot allocate anonymous inode: %d\n", ret);
		goto err_free;
	}

/*
static inline bool drm_core_check_feature(struct drm_device *dev, int feature)
{
	return dev->driver->driver_features & feature;
}
*/
/* 检查驱动是否支持这个渲染的feature */
	if (drm_core_check_feature(dev, DRIVER_RENDER)) {
		ret = drm_minor_alloc(dev, DRM_MINOR_RENDER);
		if (ret)
			goto err_minors;
	}

	ret = drm_minor_alloc(dev, DRM_MINOR_PRIMARY);
	if (ret)
		goto err_minors;

/*

static int drm_minor_alloc(struct drm_device *dev, unsigned int type)
{
...
/*分配设备号*/
	*drm_minor_get_slot(dev, type) = minor;
/* 在这里对应的类型上面填上
static struct drm_minor **drm_minor_get_slot(struct drm_device *dev,
					     unsigned int type)
{
	switch (type) {
	case DRM_MINOR_PRIMARY:
		return &dev->primary;
	case DRM_MINOR_RENDER:
		return &dev->render;
	default:
		BUG();
	}
}
*/
	return 0;
...
}


*/


	ret = drm_ht_create(&dev->map_hash, 12);
	if (ret)
		goto err_minors;

	drm_legacy_ctxbitmap_init(dev);
/* 看这个是否支持gem 如果是初始化vma_offset_manager字段 */
	if (drm_core_check_feature(dev, DRIVER_GEM)) {
		ret = drm_gem_init(dev);
		if (ret) {
			DRM_ERROR("Cannot initialize graphics execution manager (GEM)\n");
			goto err_ctxbitmap;
		}
	}
...

}
```

然后是`register`，大致流程如下所示。

![请添加图片描述](./assets/pics/ae55b9ceef9f79dfefbf9ab1ec80c4b4.png)



以plane为例。

```
int drm_dev_register(struct drm_device *dev, unsigned long flags)
{
...
	ret = drm_minor_register(dev, DRM_MINOR_RENDER);
	if (ret)
		goto err_minors;
	/* 此函数会调用device_add 可以看到是上层的调用此函数，然后添加device向kernel */
	ret = drm_minor_register(dev, DRM_MINOR_PRIMARY);
	if (ret)
		goto err_minors;
...
	if (drm_core_check_feature(dev, DRIVER_MODESET))
		drm_modeset_register_all(dev);
...
}

int drm_modeset_register_all(struct drm_device *dev)
{
...
	ret = drm_plane_register_all(dev);
	if (ret)
		goto err_plane;

	ret = drm_crtc_register_all(dev);
	if  (ret)
		goto err_crtc;

	ret = drm_encoder_register_all(dev);
	if (ret)
		goto err_encoder;

	ret = drm_connector_register_all(dev);
	if (ret)
		goto err_connector;
...
}

/* 可以看到最后都是调用的对应obj的late_register回调 */
int drm_plane_register_all(struct drm_device *dev)
{
	struct drm_plane *plane;
	int ret = 0;

	drm_for_each_plane(plane, dev) {
		if (plane->funcs->late_register)
			ret = plane->funcs->late_register(plane);
		if (ret)
			return ret;
	}

	return 0;
}
```

## drm_mm

```
通用简单内存管理器实现。旨在用作更高级内存管理器的基类实现。
请注意，所使用的算法非常简单，如果实现更智能的自由列表，可能会有显著的性能提升。
目前，它只是一个无序的自由区域堆栈。
如果使用RB树，这很容易得到改善。至少如果我们预计会出现严重的碎片化。统一分配也可以看到改善。
```

```
drm_mm提供了一个简单的范围分配器。如果适合的话，驱动程序可以自由使用linux内核中的资源分配器，drm_mm的好处是它位于drm内核中。这意味着它更容易扩展到GPU的一些更疯狂的特殊用途需求。主数据结构是&drm_mm，分配在&drm_mm_node中跟踪。驱动程序可以自由地将它们中的任何一个嵌入到自己合适的数据结构中。
drm_mm本身不会进行任何内存分配，因此，如果驱动程序选择不嵌入节点，它们仍然需要自己分配。范围分配器还支持预分配块的保留。这对于从固件接管初始模式设置配置非常有用，因为需要创建一个与固件的扫描目标完全匹配的对象。只要范围仍然是空闲的，它就可以在分配器初始化后的任何时候插入，这有助于避免驱动程序加载序列中的循环依赖。drm_mm维护了一堆最近释放的hole，在所有简单的数据结构中，这似乎是一种相当不错的聚类分配和避免过多碎片化的方法。这意味着可用空间搜索为O（num_holes）。考虑到drm_mm支持的所有花哨功能，更好的东西会相当复杂，而且由于gfx的颠簸是一个相当陡峭的悬崖，所以这不是一个真正的问题。再次删除节点是O（1）。
drm_mm支持一些功能：可以提供对齐和范围限制。此外，每个&drm_mm_node都有一个颜色值（它只是一个不透明的无符号long），结合驱动程序回调可以用来实现复杂的放置限制。i915 DRM驱动程序使用此功能在图形TT中的不兼容缓存域之间实现保护页面。
搜索和分配支持两种行为：自下而上和自上而下。默认设置为自下而上。如果内存区域有不同的限制，或者只是为了减少碎片，可以使用自上而下的分配。最后，提供了遍历所有节点和所有漏洞的迭代助手，以及一些用于调试的基本分配器转储器。请注意，此范围分配器不是线程安全的，驱动程序需要使用自己的锁定来保护修改。这背后的想法是，对于一个完整的内存管理器，无论如何都需要保护额外的数据，因此内部锁定将是完全多余的。
```



```
struct drm_mm {
    struct list_head hole_stack; // 所有含有空洞的节点的链表
    struct drm_mm_node head_node; // 所有的已分配的节点的链表, 按照起始地址升序排序
    struct list_head unused_nodes; // drm_mm_node结构体的cache链表
    int num_unused; // cache链表中的个数
    spinlock_t unused_lock; // 用于保护cache链表
    unsigned int scan_check_range : 1; // 用户是否指定地址的范围
    unsigned scan_alignment; // 检查的对齐要求
    unsigned long scan_color; // 检查的color设置
    unsigned long scan_size; // 希望的空洞的大小
    unsigned long scan_hit_start; // 标记找到的空洞的起始地址
    unsigned long scan_hit_end; // 标记找到的空洞的尾地址
    unsigned scanned_blocks; // 记录经过检查的节点的个数
    unsigned long scan_start; // 用户指定的范围的开始地址
    unsigned long scan_end; // 用户指定的范围的结束地址
    struct drm_mm_node *prev_scanned_node; // 所有经过检查的节点的链表

    void (*color_adjust)(struct drm_mm_node *node, unsigned long color,
                 unsigned long *start, unsigned long *end); // 对符合的条件的节点进行可选的地址范围的调整
};
```

```
struct drm_mm_node {
	struct list_head node_list; // 在drm_mm的全局链表中的位置
	struct list_head hole_stack; // 若该节点后面存在空洞，在表示在drm_mm的hole_stack的位置
	unsigned hole_follows : 1; // 该节点后面是否存在空洞
	unsigned scanned_block : 1; // 检查器是否检查过该节点
	unsigned scanned_prev_free : 1; // 暂时没用
	unsigned scanned_next_free : 1; // 暂时没用
	unsigned scanned_preceeds_hole : 1; // 保存在检查之前该节点的前一个节点是否有空洞，用于状态恢复
	unsigned allocated : 1; // 该节点是否被分配使用
	unsigned long color; // 用于地址调整的颜色值
	unsigned long start; // 占用的地址范围的开始
	unsigned long size; // 占用的地址范围的结束
	struct drm_mm *mm; // 指向所属的分配器
};
```

看这个文件导出了那些符号？

```
EXPORT_SYMBOL(__drm_mm_interval_first);

/* 初始化mm */
EXPORT_SYMBOL(drm_mm_init);
/* 插入预初始化节点 */
EXPORT_SYMBOL(drm_mm_reserve_node);
/* 在分配器的range空间中搜索一段空间并插入node */
EXPORT_SYMBOL(drm_mm_insert_node_in_range);
/* 从分配器中删除node */
EXPORT_SYMBOL(drm_mm_remove_node);
/* 将分配器中将old-node移动到new-node */
EXPORT_SYMBOL(drm_mm_replace_node);

/* 下述函数与结构体用到的较少，略过 */
struct drm_mm_scan
EXPORT_SYMBOL(drm_mm_scan_init_with_range);
EXPORT_SYMBOL(drm_mm_scan_add_block);
EXPORT_SYMBOL(drm_mm_scan_remove_block);
EXPORT_SYMBOL(drm_mm_scan_color_evict);


/* 清理分配器 */
EXPORT_SYMBOL(drm_mm_takedown);
/* 打印这个分配器的状态 */
EXPORT_SYMBOL(drm_mm_print);
```

![CleanShot 2024-12-26 at 14.43.50](./assets/pics/CleanShot%202024-12-26%20at%2014.43.50.png)

等等，这样就能确定只有这些文件引用了这个函数吗？

我才用的是`bear`生成`compile_commands.json`加上`clangd`服务的方式，生成的代码调转，在查看引用此函数的文件时并没有找到！

![CleanShot 2024-12-26 at 14.51.37](./assets/pics/CleanShot%202024-12-26%20at%2014.51.37.png)

但是这样并不能确保没有这个的引用，只能说明当前编译的代码里面没有用到它。但不能确保所有代码都没有用到它。所以说可以用全局搜索的方式。或者

```
https://elixir.bootlin.com/linux/v6.12.6/source/drivers/gpu/drm/drm_mm.c#L732
```

这个网站上，查找符号。但是生成函数调用图之后很复杂，他应该是上述函数被引用的很多。很多都是i915的。

```
drm/i915 驱动程序支持所有（某些非常早期的型号除外）带有 Intel 显示和渲染模块的集成 GFX 芯片组。这不包括带有 SGX 渲染单元的一组 SoC 平台，这些平台通过 gma500 drm 驱动程序获得基本支持。
```

然后就完了吗？其实并没有。为什么要这么做，因为这样搞的话只需要包含头文件即可使用该函数。

```
static inline void drm_mm_scan_init(struct drm_mm_scan *scan,
				    struct drm_mm *mm,
				    u64 size,
				    u64 alignment,
				    unsigned long color,
				    enum drm_mm_insert_mode mode)
{
	drm_mm_scan_init_with_range(scan, mm,
				    size, alignment, color,
				    0, U64_MAX, mode);
}
```

所以说还得看这个内联的引用。

#### drm_mm_init

```
/**
 * drm_mm_init - initialize a drm-mm allocator
 * @mm: the drm_mm structure to initialize
 * @start: start of the range managed by @mm
 * @size: end of the range managed by @mm
 *
 * Note that @mm must be cleared to 0 before calling this function.
 */
void drm_mm_init(struct drm_mm *mm, u64 start, u64 size)
{
	DRM_MM_BUG_ON(start + size <= start);

	mm->color_adjust = NULL;

	INIT_LIST_HEAD(&mm->hole_stack);
	mm->interval_tree = RB_ROOT_CACHED;
	mm->holes_size = RB_ROOT_CACHED;
	mm->holes_addr = RB_ROOT;

	/* 这个trick应该是start设为start+size，然后size设成-size，但是他的作用还不清楚！ */
	/* Clever trick to avoid a special case in the free hole tracking. */
	INIT_LIST_HEAD(&mm->head_node.node_list);
	/* 可以看到实际的内容还未分配 */
	mm->head_node.allocated = false;
	/* 指向自身 */
	mm->head_node.mm = mm;
	mm->head_node.start = start + size;
	mm->head_node.size = -size;
	/* 从这个函数可以看出，所谓初始化mm实际上是初始化一个mm_node并包上一层mm */
	add_hole(&mm->head_node);

	mm->scan_active = 0;
}
EXPORT_SYMBOL(drm_mm_init);
```

#### drm_mm_insert_node

```
static inline int drm_mm_insert_node(struct drm_mm *mm,
				     struct drm_mm_node *node,
				     u64 size)
{
	return drm_mm_insert_node_generic(mm, node, size, 0, 0, 0);
}

static inline int
drm_mm_insert_node_generic(struct drm_mm *mm, struct drm_mm_node *node,
			   u64 size, u64 alignment,
			   unsigned long color,
			   enum drm_mm_insert_mode mode)
{
	return drm_mm_insert_node_in_range(mm, node,
					   size, alignment, color,
					   0, U64_MAX, mode);
}
drm_mm_insert_node_in_range(mm,node,size,0,0,0,U64_MAX,0)
```

```
/**
 * drm_mm_insert_node_in_range - ranged search for space and insert @node
 * @mm: drm_mm to allocate from
 * @node: preallocate node to insert
 * @size: size of the allocation
 * @alignment: alignment of the allocation 分配的一致性
 * @color: opaque tag value to use for this node 0
 * @range_start: start of the allowed range for this node 0
 * @range_end: end of the allowed range for this node U64_MAX
 * @mode: fine-tune the allocation search and placement 控制搜索和分配行为
 从找到的孔的底部分配节点。0
 *
 * The preallocated @node must be cleared to 0.
 *
 * Returns:
 * 0 on success, -ENOSPC if there's no suitable hole.
 */
 drm_mm_insert_node_in_range(mm,node,size,0,0,0,U64_MAX,0)
int drm_mm_insert_node_in_range(struct drm_mm * const mm,
				struct drm_mm_node * const node,
				u64 size, u64 alignment,
				unsigned long color,
				u64 range_start, u64 range_end,
				enum drm_mm_insert_mode mode)
{
	struct drm_mm_node *hole;
	u64 remainder_mask;
	bool once;

	DRM_MM_BUG_ON(range_start >= range_end);

	if (unlikely(size == 0 || range_end - range_start < size))
		return -ENOSPC;

	if (rb_to_hole_size_or_zero(rb_first_cached(&mm->holes_size)) < size)
		return -ENOSPC;

	if (alignment <= 1)
		alignment = 0;

	once = mode & DRM_MM_INSERT_ONCE;
	mode &= ~DRM_MM_INSERT_ONCE;

	remainder_mask = is_power_of_2(alignment) ? alignment - 1 : 0;
	for (hole = first_hole(mm, range_start, range_end, size, mode);
	     hole;
	     hole = once ? NULL : next_hole(mm, hole, mode)) {
		u64 hole_start = __drm_mm_hole_node_start(hole);
		u64 hole_end = hole_start + hole->hole_size;
		u64 adj_start, adj_end;
		u64 col_start, col_end;

		if (mode == DRM_MM_INSERT_LOW && hole_start >= range_end)
			break;

		if (mode == DRM_MM_INSERT_HIGH && hole_end <= range_start)
			break;

		col_start = hole_start;
		col_end = hole_end;
		if (mm->color_adjust)
			mm->color_adjust(hole, color, &col_start, &col_end);

		adj_start = max(col_start, range_start);
		adj_end = min(col_end, range_end);

		if (adj_end <= adj_start || adj_end - adj_start < size)
			continue;

		if (mode == DRM_MM_INSERT_HIGH)
			adj_start = adj_end - size;

		if (alignment) {
			u64 rem;

			if (likely(remainder_mask))
				rem = adj_start & remainder_mask;
			else
				div64_u64_rem(adj_start, alignment, &rem);
			if (rem) {
				adj_start -= rem;
				if (mode != DRM_MM_INSERT_HIGH)
					adj_start += alignment;

				if (adj_start < max(col_start, range_start) ||
				    min(col_end, range_end) - adj_start < size)
					continue;

				if (adj_end <= adj_start ||
				    adj_end - adj_start < size)
					continue;
			}
		}

		node->mm = mm;
		node->size = size;
		node->start = adj_start;
		node->color = color;
		node->hole_size = 0;

		list_add(&node->node_list, &hole->node_list);
		drm_mm_interval_tree_add_node(hole, node);
		node->allocated = true;

		rm_hole(hole);
		if (adj_start > hole_start)
			add_hole(hole);
		if (adj_start + size < hole_end)
			add_hole(node);

		save_stack(node);
		return 0;
	}

	return -ENOSPC;
}
```

Emmm，看懂一点点，很多关于rb的操作就看不懂了，主要是`linux kernel` 的`rb`部分没看过，额`rb`也没看过。

可以看到，这个文件的内容和描述差不多，提供了一个基于`rb`树的分配器，可以直接被上层拥有`i915/test/`等。也可以被`vm`包装一层，然后给更上层使用。

## drm_vma_manager

这个文件的内容，gpt总结如下：

VMA 管理器负责将驱动程序依赖的内存区域映射到线性用户地址空间，提供给调用者偏移量以便在 DRM 设备的 `address_space` 中使用，同时确保区域不重叠、大小适当，并避免因虚假 `vm_pgoff` 字段导致虚拟内存管理核心（mm-core）混乱。该管理器专为用户空间虚拟内存的映射设计，不应用于 VMEM 中对象的放置。其实现基于 `drm_mm` 进行内存对象的分配和释放，但由于 `drm_mm` 更适合分配和释放操作而非查找，因此额外使用红黑树（RB-tree）优化偏移查找。需要注意，每个 `address_space` 上只能使用一个偏移管理器，否则会破坏虚拟内存的线性结构，导致 mm-core 无法正确拆除内存映射。此外，该管理器以页为单位操作，所有参数和返回值（除 `drm_vma_node_offset_addr()` 外）均以页为单位，要求对象大小和偏移量始终页对齐。访问管理方面，需通过 `drm_vma_node_allow()` 授权打开文件上下文访问特定节点，若需撤销访问，可使用 `drm_vma_node_revoke()`，但调用者需负责销毁现有的映射（如有必要）。如果需要基于字节的用户空间地址，可通过 `drm_vma_node_offset_addr()` 获取。总之，该管理器通过对齐、避免重叠和管理访问权限，简化了用户空间映射的管理。

```
EXPORT_SYMBOL(drm_vma_offset_manager_init);
EXPORT_SYMBOL(drm_vma_offset_manager_destroy);
/* 上述两个直接调用了drm_mm_takedown(&mgr->vm_addr_space_mm);
   drm_mm_init(&mgr->vm_addr_space_mm, page_offset, size); */

/* 使用mm中的接口完成 */
EXPORT_SYMBOL(drm_vma_offset_add);
EXPORT_SYMBOL(drm_vma_offset_remove);


EXPORT_SYMBOL(drm_vma_offset_lookup_locked);
EXPORT_SYMBOL(drm_vma_node_allow);
EXPORT_SYMBOL(drm_vma_node_revoke);
EXPORT_SYMBOL(drm_vma_node_is_allowed);
```



```
这个函数基本上包装的drm_mm_insert_node的内容。
本质上是将drm_vma_offset_node的node添加到drm_vma_offset_manager的mm中

@pages 的值并不需要与底层内存对象的实际大小一致。
它仅限制了用户空间能够映射的内存范围大小。
使用了锁，可见本意是使得其线程安全

int drm_vma_offset_add(struct drm_vma_offset_manager *mgr,
		       struct drm_vma_offset_node *node, unsigned long pages)
{
	int ret = 0;

	write_lock(&mgr->vm_lock);

	if (!drm_mm_node_allocated(&node->vm_node))
		ret = drm_mm_insert_node(&mgr->vm_addr_space_mm,
					 &node->vm_node, pages);

	write_unlock(&mgr->vm_lock);

	return ret;
}
EXPORT_SYMBOL(drm_vma_offset_add);
```

```
/**
 * drm_vma_offset_remove() - Remove offset node from manager
 * @mgr: Manager object
 * @node: Node to be removed
 *
 * Remove a node from the offset manager. If the node wasn't added before, this
 * does nothing. After this call returns, the offset and size will be 0 until a
 * new offset is allocated via drm_vma_offset_add() again. Helper functions like
 * drm_vma_node_start() and drm_vma_node_offset_addr() will return 0 if no
 * offset is allocated.
 */
void drm_vma_offset_remove(struct drm_vma_offset_manager *mgr,
			   struct drm_vma_offset_node *node)
{
	write_lock(&mgr->vm_lock);

	if (drm_mm_node_allocated(&node->vm_node)) {
		drm_mm_remove_node(&node->vm_node);
		memset(&node->vm_node, 0, sizeof(node->vm_node));
	}

	write_unlock(&mgr->vm_lock);
}
EXPORT_SYMBOL(drm_vma_offset_remove);
```



```
这三个函数，涉及到权限管理，暂时略过。
EXPORT_SYMBOL(drm_vma_node_allow);
EXPORT_SYMBOL(drm_vma_node_revoke);
EXPORT_SYMBOL(drm_vma_node_is_allowed);
```



```
在使用drm_vma_offset_lookup_locked之前，需要加锁。

/**
 * drm_vma_offset_lock_lookup() - Lock lookup for extended private use
 * @mgr: Manager object
 *
 * Lock VMA manager for extended lookups. Only locked VMA function calls
 * are allowed while holding this lock. All other contexts are blocked from VMA
 * until the lock is released via drm_vma_offset_unlock_lookup().
 *
 * Use this if you need to take a reference to the objects returned by
 * drm_vma_offset_lookup_locked() before releasing this lock again.
 *
 * This lock must not be used for anything else than extended lookups. You must
 * not call any other VMA helpers while holding this lock.
 *
 * Note: You're in atomic-context while holding this lock!
 */
static inline void drm_vma_offset_lock_lookup(struct drm_vma_offset_manager *mgr)
{
	read_lock(&mgr->vm_lock);
}

/**
 * drm_vma_offset_unlock_lookup() - Unlock lookup for extended private use
 * @mgr: Manager object
 *
 * Release lookup-lock. See drm_vma_offset_lock_lookup() for more information.
 */
static inline void drm_vma_offset_unlock_lookup(struct drm_vma_offset_manager *mgr)
{
	read_unlock(&mgr->vm_lock);
}

 * Example:
 *
 * ::
 *
 *     drm_vma_offset_lock_lookup(mgr);
 *     node = drm_vma_offset_lookup_locked(mgr);
 *     if (node)
 *         kref_get_unless_zero(container_of(node, sth, entr));
 *     drm_vma_offset_unlock_lookup(mgr);
 *
 
 
 找到一个给定起始地址和对象大小的节点。这将返回给定节点的_best_匹配。也就是说，@start可能指向一个有效区域的某个地方，只要该节点跨越整个请求区域（给定@pages的页数大小），就会返回给定的节点。
```

这几个对象间的关系应该如下所示。没有加上`file`的部分。

![CleanShot 2024-12-27 at 16.17.07](./assets/pics/CleanShot%202024-12-27%20at%2016.17.07.png)



## drm_gem

第一个函数为`init`，这里的init指的是`drm_device`里面的vm的init，而不是`gem_obj`的`init`，而且这个函数是当`device`加载时自动调用，生成这个管理器，很合理吧。

```
/**
 * drm_gem_init - Initialize the GEM device fields
 * @dev: drm_devic structure to initialize
 */
int
drm_gem_init(struct drm_device *dev)
{
	struct drm_vma_offset_manager *vma_offset_manager;

	mutex_init(&dev->object_name_lock);
	idr_init_base(&dev->object_name_idr, 1);
	/* 初始化这个vm管理器 */
	vma_offset_manager = kzalloc(sizeof(*vma_offset_manager), GFP_KERNEL);
	if (!vma_offset_manager) {
		DRM_ERROR("out of memory\n");
		return -ENOMEM;
	}
	/* 建立映射关系 */
	dev->vma_offset_manager = vma_offset_manager;
	/* 初始化，这个函数上面也介绍了 实际上是初始化一块drm_mm的区域*/
	drm_vma_offset_manager_init(vma_offset_manager,
				    DRM_FILE_PAGE_OFFSET_START,
				    DRM_FILE_PAGE_OFFSET_SIZE);

	return 0;
}

```

```
2.1 drm_dev_init
该函数用来创建一个 drm_dev. 每一个 drm 系统都需要创建一个 drm_dev 来和 kms 中的 obj 进行交互…

对应成员变量的简单初始化
检测 driver 的 driver_features 标志位是否设置 DRIVER_RENDER , 有则创建对应的设备 dev/dri/enderD(128 - 192)
创建一个 DRM_MINOR_PRIMARY 子设备, 每个 drm_dev 必须有一个默认的 DRM_MINOR_PRIMARY 设备 dev/dri/card(0 - 64)
检测 driver 的 driver_features 标志位是否设置 DRIVER_GEM , 如果设置了则会为我们分配并创建一个默认的起始偏移地址为 DRM_FILE_PAGE_OFFSET_START内存大小为 DRM_FILE_PAGE_OFFSET_SIZE的 vma_offset_manager
将父设备名称用作 DRM 设备的唯一标识符 unique(drm dev的成员变量)，没有父设备则使用驱动程序名称作为 unique 唯一标识符.
小贴士: 这个接口仅仅创建并初始设备化并不会注册
```

```
void
drm_gem_destroy(struct drm_device *dev)
{

	drm_vma_offset_manager_destroy(dev->vma_offset_manager);
	kfree(dev->vma_offset_manager);
	dev->vma_offset_manager = NULL;
}
```

那么这个函数应该就是取消映射关系，并且销毁`vm_manager`。

上述两个函数属于`device`加载时被调用的。那么好奇的是这个`device`什么时候被创建，按理来说，一个`device`是硬件的抽象，一般情况是通过设备树加载进来，那么这个`drm_device`代表的什么？什么时候被加载，是硬件还是抽象。通过代码搜索，这个被一堆GPU驱动调用，但是在rk中，有如下操作。

```
static int rockchip_drm_bind(struct device *dev)
{
	struct drm_device *drm_dev;
	struct rockchip_drm_private *private;
	int ret;

	/* Remove existing drivers that may own the framebuffer memory. */
	ret = drm_aperture_remove_framebuffers(&rockchip_drm_driver);
	if (ret) {
		DRM_DEV_ERROR(dev,
			      "Failed to remove existing framebuffers - %d.\n",
			      ret);
		return ret;
	}

	drm_dev = drm_dev_alloc(&rockchip_drm_driver, dev);
	if (IS_ERR(drm_dev))
		return PTR_ERR(drm_dev);
```

最后到了这个地方。

```

/**
 * struct component_master_ops - callback for the aggregate driver
 *
 * Aggregate drivers are registered with component_master_add_with_match() and
 * unregistered with component_master_del().
 */
struct component_master_ops {
	/**
	 * @bind:
	 *
	 * Called when all components or the aggregate driver, as specified in
	 * the match list passed to component_master_add_with_match(), are
	 * ready. Usually there are 3 steps to bind an aggregate driver:
	 *
	 * 1. Allocate a structure for the aggregate driver.
	 *
	 * 2. Bind all components to the aggregate driver by calling
	 *    component_bind_all() with the aggregate driver structure as opaque
	 *    pointer data.
	 *
	 * 3. Register the aggregate driver with the subsystem to publish its
	 *    interfaces.
	 *
	 * Note that the lifetime of the aggregate driver does not align with
	 * any of the underlying &struct device instances. Therefore devm cannot
	 * be used and all resources acquired or allocated in this callback must
	 * be explicitly released in the @unbind callback.
	 */
	int (*bind)(struct device *master);
	/**
	 * @unbind:
	 *
	 * Called when either the aggregate driver, using
	 * component_master_del(), or one of its components, using
	 * component_del(), is unregistered.
	 */
	void (*unbind)(struct device *master);
};
```

因为`gem`不仅仅支持GPU，还支持CPU，所以假设当没有GPU仅有CPU的情况下，这个东西也是可用的。那么就应该存在各家平台对这个的支持，那么就应该落在了[component_master_ops](https://elixir.bootlin.com/linux/v6.12.6/C/ident/component_master_ops)，接下来注意这个东西。

接下来看`gem_object`的操作。

还是习惯性的从`EXPORT_SYMBOL`开始看。

```
EXPORT_SYMBOL(drm_gem_object_init);
EXPORT_SYMBOL(drm_gem_private_object_init);
EXPORT_SYMBOL(drm_gem_object_release);
EXPORT_SYMBOL(drm_gem_object_free);
EXPORT_SYMBOL(drm_gem_object_put_unlocked);
EXPORT_SYMBOL(drm_gem_object_put);

EXPORT_SYMBOL(drm_gem_handle_create);
EXPORT_SYMBOL(drm_gem_handle_delete);
EXPORT_SYMBOL(drm_gem_object_lookup);

EXPORT_SYMBOL_GPL(drm_gem_dumb_map_offset);
EXPORT_SYMBOL(drm_gem_dumb_destroy);

EXPORT_SYMBOL(drm_gem_create_mmap_offset_size);
EXPORT_SYMBOL(drm_gem_create_mmap_offset);
EXPORT_SYMBOL(drm_gem_mmap_obj);
EXPORT_SYMBOL(drm_gem_mmap);
EXPORT_SYMBOL(drm_gem_free_mmap_offset);

EXPORT_SYMBOL(drm_gem_get_pages);
EXPORT_SYMBOL(drm_gem_put_pages);

EXPORT_SYMBOL(drm_gem_vm_open);
EXPORT_SYMBOL(drm_gem_vm_close);
```

#### 关于gem_obj的操作

```
/**
 * drm_gem_object_init - initialize an allocated shmem-backed GEM object
 * @dev: drm_device the object should be initialized for
 * @obj: drm_gem_object to initialize
 * @size: object size
 *
 * Initialize an already allocated GEM object of the specified size with
 * shmfs backing store.
 */
int drm_gem_object_init(struct drm_device *dev,
			struct drm_gem_object *obj, size_t size)
{
	struct file *filp;

	drm_gem_private_object_init(dev, obj, size);

/*
shmem_file_setup 是 Linux 内核中用于创建匿名共享内存文件的一个函数。它主要用于为内核子系统分配一段临时内存（通常是页缓存支持的匿名文件），以便在用户空间和内核之间共享数据，或者在内核内部使用。以下是其功能和作用的详细说明：

函数功能
shmem_file_setup 函数的主要功能是创建一个临时的、匿名的内存文件，支持共享内存的分配和管理。该文件的内容存储在内核的页缓存中，可以通过文件描述符访问。
*/

	filp = shmem_file_setup("drm mm object", size, VM_NORESERVE);
	if (IS_ERR(filp))
		return PTR_ERR(filp);

	obj->filp = filp;

	return 0;
}
EXPORT_SYMBOL(drm_gem_object_init);

/**
 * drm_gem_private_object_init - initialize an allocated private GEM object
 * @dev: drm_device the object should be initialized for
 * @obj: drm_gem_object to initialize
 * @size: object size
 *
 * Initialize an already allocated GEM object of the specified size with
 * no GEM provided backing store. Instead the caller is responsible for
 * backing the object and handling it.
 */
void drm_gem_private_object_init(struct drm_device *dev,
				 struct drm_gem_object *obj, size_t size)
{
	BUG_ON((size & (PAGE_SIZE - 1)) != 0);

	obj->dev = dev;
	obj->filp = NULL;

	kref_init(&obj->refcount);
	obj->handle_count = 0;
	obj->size = size;
	drm_vma_node_reset(&obj->vma_node);
}
EXPORT_SYMBOL(drm_gem_private_object_init);
```

简言之，搞到一段共享内存，建立`drm_device`与`drm_gen_object`与共享内存的关系。

```
/**
 * drm_gem_object_release - release GEM buffer object resources
 * @obj: GEM buffer object
 *
 * This releases any structures and resources used by @obj and is the invers of
 * drm_gem_object_init().
 */
void
drm_gem_object_release(struct drm_gem_object *obj)
{
	WARN_ON(obj->dma_buf);

	if (obj->filp)
		fput(obj->filp);

	drm_gem_free_mmap_offset(obj);
}
EXPORT_SYMBOL(drm_gem_object_release);

/**
 * drm_gem_object_free - free a GEM object
 * @kref: kref of the object to free
 *
 * Called after the last reference to the object has been lost.
 * Must be called holding &drm_device.struct_mutex.
 *
 * Frees the object
 */
void
drm_gem_object_free(struct kref *kref)
{
	struct drm_gem_object *obj =
		container_of(kref, struct drm_gem_object, refcount);
	struct drm_device *dev = obj->dev;

	if (dev->driver->gem_free_object_unlocked) {
		dev->driver->gem_free_object_unlocked(obj);
	} else if (dev->driver->gem_free_object) {
		WARN_ON(!mutex_is_locked(&dev->struct_mutex));

		dev->driver->gem_free_object(obj);
	}
}
EXPORT_SYMBOL(drm_gem_object_free);
```

可以看到`release`的是资源，`free`的是`obj`。仅仅是当前`obj`而不是`dev`。

```
EXPORT_SYMBOL(drm_gem_object_put);
EXPORT_SYMBOL(drm_gem_object_put_unlocked);
一个是增加buf的引用计数一个是减少。注意是gem_obj的而不是drm_dev的。
```

#### 关于handler的操作

```
/**
 * drm_gem_object_lookup - look up a GEM object from it's handle
 * @filp: DRM file private date
 * @handle: userspace handle
 *
 * Returns:
 *
 * A reference to the object named by the handle if such exists on @filp, NULL
 * otherwise.
 */
struct drm_gem_object *
drm_gem_object_lookup(struct drm_file *filp, u32 handle)
{
	struct drm_gem_object *obj;

	spin_lock(&filp->table_lock);

	/* Check if we currently have a reference on the object */
	obj = idr_find(&filp->object_idr, handle);
	if (obj)
		drm_gem_object_get(obj);

	spin_unlock(&filp->table_lock);

	return obj;
}
EXPORT_SYMBOL(drm_gem_object_lookup);
```

可以看到这里的`lookup`指的是根据`handler`找到对应的`obj`，原理就是`idr`。所以上层看起来很神奇的`handler`，实际上只是一个`idr`。实际上是通过如下实现的。

```
void *idr_find(const struct idr *idr, unsigned long id)
{
	return radix_tree_lookup(&idr->idr_rt, id - idr->idr_base);
}
```

然后如下两个函数应该和这个函数是一类的。

```
EXPORT_SYMBOL(drm_gem_handle_create);
EXPORT_SYMBOL(drm_gem_handle_delete);
```



```
/**
 * drm_gem_handle_delete - deletes the given file-private handle
 * @filp: drm file-private structure to use for the handle look up
 * @handle: userspace handle to delete
 *
 * Removes the GEM handle from the @filp lookup table which has been added with
 * drm_gem_handle_create(). If this is the last handle also cleans up linked
 * resources like GEM names.
 */
int
drm_gem_handle_delete(struct drm_file *filp, u32 handle)
{
	struct drm_gem_object *obj;

	spin_lock(&filp->table_lock);

	/* Check if we currently have a reference on the object */
	obj = idr_replace(&filp->object_idr, NULL, handle);
	spin_unlock(&filp->table_lock);
	if (IS_ERR_OR_NULL(obj))
		return -EINVAL;

	/* Release driver's reference and decrement refcount. */
	drm_gem_object_release_handle(handle, obj, filp);

	/* And finally make the handle available for future allocations. */
	spin_lock(&filp->table_lock);
	idr_remove(&filp->object_idr, handle);
	spin_unlock(&filp->table_lock);

	return 0;
}
EXPORT_SYMBOL(drm_gem_handle_delete);

/**
 * drm_gem_handle_create - create a gem handle for an object
 * @file_priv: drm file-private structure to register the handle for
 * @obj: object to register
 * @handlep: pionter to return the created handle to the caller
 *
 * Create a handle for this object. This adds a handle reference to the object,
 * which includes a regular reference count. Callers will likely want to
 * dereference the object afterwards.
 *
 * Since this publishes @obj to userspace it must be fully set up by this point,
 * drivers must call this last in their buffer object creation callbacks.
 */
int drm_gem_handle_create(struct drm_file *file_priv,
			  struct drm_gem_object *obj,
			  u32 *handlep)
{
	mutex_lock(&obj->dev->object_name_lock);

	return drm_gem_handle_create_tail(file_priv, obj, handlep);
}
EXPORT_SYMBOL(drm_gem_handle_create);
/**
 * drm_gem_handle_create_tail - internal functions to create a handle
 * @file_priv: drm file-private structure to register the handle for
 * @obj: object to register
 * @handlep: pointer to return the created handle to the caller
 *
 * This expects the &drm_device.object_name_lock to be held already and will
 * drop it before returning. Used to avoid races in establishing new handles
 * when importing an object from either an flink name or a dma-buf.
 *
 * Handles must be release again through drm_gem_handle_delete(). This is done
 * when userspace closes @file_priv for all attached handles, or through the
 * GEM_CLOSE ioctl for individual handles.
 */
int
drm_gem_handle_create_tail(struct drm_file *file_priv,
			   struct drm_gem_object *obj,
			   u32 *handlep)
{
	struct drm_device *dev = obj->dev;
	u32 handle;
	int ret;

	WARN_ON(!mutex_is_locked(&dev->object_name_lock));
	if (obj->handle_count++ == 0)
		drm_gem_object_get(obj);

	/*
	 * Get the user-visible handle using idr.  Preload and perform
	 * allocation under our spinlock.
	 */
	idr_preload(GFP_KERNEL);
	spin_lock(&file_priv->table_lock);

	ret = idr_alloc(&file_priv->object_idr, obj, 1, 0, GFP_NOWAIT);

	spin_unlock(&file_priv->table_lock);
	idr_preload_end();

	mutex_unlock(&dev->object_name_lock);
	if (ret < 0)
		goto err_unref;

	handle = ret;

	ret = drm_vma_node_allow(&obj->vma_node, file_priv);
	if (ret)
		goto err_remove;

	if (dev->driver->gem_open_object) {
		ret = dev->driver->gem_open_object(obj, file_priv);
		if (ret)
			goto err_revoke;
	}

	*handlep = handle;
	return 0;

err_revoke:
	drm_vma_node_revoke(&obj->vma_node, file_priv);
err_remove:
	spin_lock(&file_priv->table_lock);
	idr_remove(&file_priv->object_idr, handle);
	spin_unlock(&file_priv->table_lock);
err_unref:
	drm_gem_object_handle_put_unlocked(obj);
	return ret;
}
```

这里需要主要的是用到了如下vm提供的函数。用于权限管理？ *Add open-file to list of allowed users*

```
ret = drm_vma_node_allow(&obj->vma_node, file_priv);
drm_gem_object_release_handle(handle, obj, filp);
```



#### 关于mmap的操作

```
/**
 * drm_gem_create_mmap_offset_size - create a fake mmap offset for an object
 * @obj: obj in question
 * @size: the virtual size
 *
 * GEM memory mapping works by handing back to userspace a fake mmap offset
 * it can use in a subsequent mmap(2) call.  The DRM core code then looks
 * up the object based on the offset and sets up the various memory mapping
 * structures.
 *
 * This routine allocates and attaches a fake offset for @obj, in cases where
 * the virtual size differs from the physical size (ie. &drm_gem_object.size).
 * Otherwise just use drm_gem_create_mmap_offset().
 *
 * This function is idempotent and handles an already allocated mmap offset
 * transparently. Drivers do not need to check for this case.
 */
int
drm_gem_create_mmap_offset_size(struct drm_gem_object *obj, size_t size)
{
	struct drm_device *dev = obj->dev;

	return drm_vma_offset_add(dev->vma_offset_manager, &obj->vma_node,
				  size / PAGE_SIZE);
}
EXPORT_SYMBOL(drm_gem_create_mmap_offset_size);

/**
 * drm_gem_create_mmap_offset - create a fake mmap offset for an object
 * @obj: obj in question
 *
 * GEM memory mapping works by handing back to userspace a fake mmap offset
 * it can use in a subsequent mmap(2) call.  The DRM core code then looks
 * up the object based on the offset and sets up the various memory mapping
 * structures.
 *
 * This routine allocates and attaches a fake offset for @obj.
 *
 * Drivers can call drm_gem_free_mmap_offset() before freeing @obj to release
 * the fake offset again.
 */
int drm_gem_create_mmap_offset(struct drm_gem_object *obj)
{
	return drm_gem_create_mmap_offset_size(obj, obj->size);
}
EXPORT_SYMBOL(drm_gem_create_mmap_offset);
```

可以看到最终是将`vm_node`加入到`vm_manager`中管理。下面是函数调用栈。

```
v=drmIoctl(fd, DRM_IOCTL_MODE_CREATE_DUMB, &create); --> // 开放给上层的 libdrm 接口
    drm_gem_cma_dumb_create() -->
        drm_gem_cma_create_with_handle() -->
            drm_gem_cma_create() -->
                __drm_gem_cma_create() -->
                    if (drm->driver->gem_create_object) // 回调 gem_create_object 接口创建 gem_obj 
                        gem_obj = drm->driver->gem_create_object(drm, size); 
                    else
                        gem_obj = kzalloc(sizeof(*cma_obj), GFP_KERNEL); // 创建一个 gem obj
                    drm_gem_create_mmap_offset() -->    
                        drm_gem_create_mmap_offset_size() -->
                            drm_vma_offset_add() -->
                                drm_mm_insert_node() --> // 在 drm_mm 中查找到空闲可用的空间, 然后插入一个 drm_vma_offset_node 表示这个可用的空间.
                dma_alloc_wc() // 申请物理内存, 并将内存地址保存到 cma_obj

```

```
/**
 * drm_gem_mmap_obj - memory map a GEM object
 * @obj: the GEM object to map
 * @obj_size: the object size to be mapped, in bytes
 * @vma: VMA for the area to be mapped
 *
 * Set up the VMA to prepare mapping of the GEM object using the gem_vm_ops
 * provided by the driver. Depending on their requirements, drivers can either
 * provide a fault handler in their gem_vm_ops (in which case any accesses to
 * the object will be trapped, to perform migration, GTT binding, surface
 * register allocation, or performance monitoring), or mmap the buffer memory
 * synchronously after calling drm_gem_mmap_obj.
 *
 * This function is mainly intended to implement the DMABUF mmap operation, when
 * the GEM object is not looked up based on its fake offset. To implement the
 * DRM mmap operation, drivers should use the drm_gem_mmap() function.
 *
 * drm_gem_mmap_obj() assumes the user is granted access to the buffer while
 * drm_gem_mmap() prevents unprivileged users from mapping random objects. So
 * callers must verify access restrictions before calling this helper.
 *
 * Return 0 or success or -EINVAL if the object size is smaller than the VMA
 * size, or if no gem_vm_ops are provided.
 */
int drm_gem_mmap_obj(struct drm_gem_object *obj, unsigned long obj_size,
		     struct vm_area_struct *vma)
{
	struct drm_device *dev = obj->dev;

	/* Check for valid size. */
	if (obj_size < vma->vm_end - vma->vm_start)
		return -EINVAL;

	if (!dev->driver->gem_vm_ops)
		return -EINVAL;

	vma->vm_flags |= VM_IO | VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP;
	vma->vm_ops = dev->driver->gem_vm_ops;
	vma->vm_private_data = obj;
	vma->vm_page_prot = pgprot_writecombine(vm_get_page_prot(vma->vm_flags));
	vma->vm_page_prot = pgprot_decrypted(vma->vm_page_prot);

	/* Take a ref for this mapping of the object, so that the fault
	 * handler can dereference the mmap offset's pointer to the object.
	 * This reference is cleaned up by the corresponding vm_close
	 * (which should happen whether the vma was created by this call, or
	 * by a vm_open due to mremap or partial unmap or whatever).
	 */
	drm_gem_object_get(obj);

	return 0;
}
EXPORT_SYMBOL(drm_gem_mmap_obj);

/**
 * drm_gem_mmap - memory map routine for GEM objects
 * @filp: DRM file pointer
 * @vma: VMA for the area to be mapped
 *
 * If a driver supports GEM object mapping, mmap calls on the DRM file
 * descriptor will end up here.
 *
 * Look up the GEM object based on the offset passed in (vma->vm_pgoff will
 * contain the fake offset we created when the GTT map ioctl was called on
 * the object) and map it with a call to drm_gem_mmap_obj().
 *
 * If the caller is not granted access to the buffer object, the mmap will fail
 * with EACCES. Please see the vma manager for more information.
 */
int drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)
{
	struct drm_file *priv = filp->private_data;
	struct drm_device *dev = priv->minor->dev;
	struct drm_gem_object *obj = NULL;
	struct drm_vma_offset_node *node;
	int ret;

	if (drm_dev_is_unplugged(dev))
		return -ENODEV;

	drm_vma_offset_lock_lookup(dev->vma_offset_manager);
	node = drm_vma_offset_exact_lookup_locked(dev->vma_offset_manager,
						  vma->vm_pgoff,
						  vma_pages(vma));
	if (likely(node)) {
		obj = container_of(node, struct drm_gem_object, vma_node);
		/*
		 * When the object is being freed, after it hits 0-refcnt it
		 * proceeds to tear down the object. In the process it will
		 * attempt to remove the VMA offset and so acquire this
		 * mgr->vm_lock.  Therefore if we find an object with a 0-refcnt
		 * that matches our range, we know it is in the process of being
		 * destroyed and will be freed as soon as we release the lock -
		 * so we have to check for the 0-refcnted object and treat it as
		 * invalid.
		 */
		if (!kref_get_unless_zero(&obj->refcount))
			obj = NULL;
	}
	drm_vma_offset_unlock_lookup(dev->vma_offset_manager);

	if (!obj)
		return -EINVAL;

	if (!drm_vma_node_is_allowed(node, priv)) {
		drm_gem_object_put_unlocked(obj);
		return -EACCES;
	}

	if (node->readonly) {
		if (vma->vm_flags & VM_WRITE) {
			drm_gem_object_put_unlocked(obj);
			return -EINVAL;
		}

		vma->vm_flags &= ~VM_MAYWRITE;
	}

	ret = drm_gem_mmap_obj(obj, drm_vma_node_size(node) << PAGE_SHIFT,
			       vma);

	drm_gem_object_put_unlocked(obj);

	return ret;
}
EXPORT_SYMBOL(drm_gem_mmap);
```

好吧这里的mmap，其实已经有点看不懂了。

可以参考这段代码。

```
int mtk_drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)
{
	struct drm_gem_object *obj;
	int ret;

	ret = drm_gem_mmap(filp, vma);
	if (ret)
		return ret;

	obj = vma->vm_private_data;

	return mtk_drm_gem_object_mmap(obj, vma);
}
```

```
static const struct file_operations mtk_drm_fops = {
	.owner = THIS_MODULE,
	.open = drm_open,
	.release = drm_release,
	.unlocked_ioctl = drm_ioctl,
	.mmap = mtk_drm_gem_mmap,
	.poll = drm_poll,
	.read = drm_read,
	.compat_ioctl = drm_compat_ioctl,
};
```

可以看到这段代码可以被fs系统调用，实现mmap回调。在mtk的代码里面，有用到了这个回调，当然可以自己实现一个类似的。在rock中也有类似的写法。

```
int rockchip_gem_mmap_buf(struct drm_gem_object *obj,
			  struct vm_area_struct *vma)
{
	int ret;

	ret = drm_gem_mmap_obj(obj, obj->size, vma);
	if (ret)
		return ret;

	return rockchip_drm_gem_object_mmap(obj, vma);
}
```

当然mmap具体如何实现的我并不关心现在。

https://www.cnblogs.com/zyly/p/17775862.html#_label1_2

https://blog.csdn.net/hexiaolong2009/article/details/107592704

https://blog.csdn.net/hexiaolong2009/article/details/102596791



#### 关于dumb的操作

```
/**
 * drm_gem_dumb_map_offset - return the fake mmap offset for a gem object
 * @file: drm file-private structure containing the gem object
 * @dev: corresponding drm_device
 * @handle: gem object handle
 * @offset: return location for the fake mmap offset
 *
 * This implements the &drm_driver.dumb_map_offset kms driver callback for
 * drivers which use gem to manage their backing storage.
 *
 * Returns:
 * 0 on success or a negative error code on failure.
 */
int drm_gem_dumb_map_offset(struct drm_file *file, struct drm_device *dev,
			    u32 handle, u64 *offset)
{
	struct drm_gem_object *obj;
	int ret;

	obj = drm_gem_object_lookup(file, handle);
	if (!obj)
		return -ENOENT;

	/* Don't allow imported objects to be mapped */
	if (obj->import_attach) {
		ret = -EINVAL;
		goto out;
	}

	ret = drm_gem_create_mmap_offset(obj);
	if (ret)
		goto out;

	*offset = drm_vma_node_offset_addr(&obj->vma_node);
out:
	drm_gem_object_put_unlocked(obj);

	return ret;
}
EXPORT_SYMBOL_GPL(drm_gem_dumb_map_offset);
```

```
/**
 * drm_gem_dumb_destroy - dumb fb callback helper for gem based drivers
 * @file: drm file-private structure to remove the dumb handle from
 * @dev: corresponding drm_device
 * @handle: the dumb handle to remove
 *
 * This implements the &drm_driver.dumb_destroy kms driver callback for drivers
 * which use gem to manage their backing storage.
 */
int drm_gem_dumb_destroy(struct drm_file *file,
			 struct drm_device *dev,
			 uint32_t handle)
{
	return drm_gem_handle_delete(file, handle);
}
EXPORT_SYMBOL(drm_gem_dumb_destroy);
```

可以看到也是通过上述`mmap`的接口完成的。

```
EXPORT_SYMBOL(drm_gem_get_pages);
EXPORT_SYMBOL(drm_gem_put_pages);
```

这两个函数一个是获取pages，一个是删除pages。

#### 关于ioctl

关于ioctl的定义在如下文件。

```
kernel/drivers/gpu/drm/drm_ioctl.c
```

例如

```
	DRM_IOCTL_DEF(DRM_IOCTL_GEM_CLOSE, drm_gem_close_ioctl, DRM_UNLOCKED|DRM_RENDER_ALLOW),
```

对应了

```
/**
 * drm_gem_close_ioctl - implementation of the GEM_CLOSE ioctl
 * @dev: drm_device
 * @data: ioctl data
 * @file_priv: drm file-private structure
 *
 * Releases the handle to an mm object.
 */
int
drm_gem_close_ioctl(struct drm_device *dev, void *data,
		    struct drm_file *file_priv)
{
	struct drm_gem_close *args = data;
	int ret;

	if (!drm_core_check_feature(dev, DRIVER_GEM))
		return -ENODEV;

	ret = drm_gem_handle_delete(file_priv, args->handle);

	return ret;
}
```

gem中提供了如下的ioctl

```
drm_gem_close_ioctl
drm_gem_flink_ioctl
drm_gem_open_ioctl
```





这里简单的介绍了gem的部分代码，包括基本对象间的关系，从顶层ioctl到mm之间的过程，但是关于mmap等额外子系统的东西只是简单介绍，并没有深入研究，还有部分代码例如cma并未深入研究。接下来根据何小龙大神的dma-buf文章，研究drm的gem如何和dma-buf联系起来的。因为很大一部分数据依赖于dma-buf子系统。







https://www.cnblogs.com/zyly/p/17686403.html#_label1

https://blog.csdn.net/sty01z/article/details/135879635

https://crab2313.github.io/post/drm-vram/

https://blog.totorow.xyz/posts/gfx_gem_mm_km/gfx_gem_mm_km/